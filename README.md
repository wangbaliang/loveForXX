# xxlove

I do it just due to my love for chenxingyi.

Chenxingyi: 
  I wanna say to u:   i really like u. Can u make my GF?



# 前端启动

## 环境配置
确保自己有node环境，在命令行输入 node -v 检查自己是否有node环境

如果没有
https://nodejs.org/zh-cn/

建议安装版本16.x

在命令行输入 yarn -v 检查自己是否有yarn

如果没有,在命令行输入,输入前确保已经安装node

npm i -g yarn

## 项目启动
cd frontEnd

yarn

yarn start

## 持久化部署
在frontEnd文件夹下
pm2 start npm -- start




##后端实现


数据上传及存储
	数据上传这块总共经过四步：1.前后端之间数据上传，2. 后端上传文件到oss云存储  3. db里保存文件记录等   4.添加发起异步任务(数据处理以及算法相关任务)
	前端基于nodejs技术采用了react antd前端架构，使用umi做项目架构。 前端上传文件，后端经过flask后端服务框架，服务端将文件接收后并通过REST API将文件上传到云oss对象存储(对象存储是基础AWS S3协议实现，可海量、安全、低成本、高可靠的云存储服务，可提供99.9999999999%（12个9）的数据持久性，99.995%的数据可用性。
	oss的访问密钥ak, sk都会加密后存在mysql db表中，文件上传后会在db表-文件表中记录其所在oss的bucket，path,以及下载链接等信息。 保存到db表后生成的主键id作为文件id，同时会作为后续对文件解析-数据处理-算法分析的整体pipline的主任务id，随后向azkaban请求添加pipline任务


任务调度模块(Azkaban)
	本项目的算法工程部分，需要对用户上传的数据包进行前期的文件解压，数据预处理，多次算法处理及结果采集与可视化等，整个pipline大任务拆分为了多个子任务并且需要前后串联调度。各大任务小任务且存在并发占用资源的关系，在设计中甚至需要支持不同用户和不同任务类型之间会有优先调度的关系，基于以上需求，任务调度模块采用了Azkaban。 Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程，整体包括三部分webserver、dbserver、executorserver，其定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。 Azkaban官网 https://azkaban.github.io/。 


数据预处理
	将文件包从oss下载到本地，然后进行zip解压后对子文件逐个进行加载后，经过内存处理xxxx，将采集到到文件信息等录入db(用于后续做可视化及报表分析) 

离线训练
	基于sklearn pytorch等算法库封装改造开发了一套算法框架，来做聚类、xxxx等算法分析，经过xxxxx, 在经过一系列调参和采用不同的模型结构进行算法实验后得到比较准确的模型，最终将模型保存到oss存储，将metrics等记录保存到db。

模型上线
	模型上线之前会推送到评测模块， 评测模块会采用预支好的测试样本进行模型预测，对预测结果进行打分评判，通过后才会推往后续上线流程。 模型服务这块采用自适应动态加载模型来提供在线服务，预测服务会动态监控固定的模型目录，当目录内的模型文件信息(名称,文件修改时间等)产生变化时，会出发hook进行重新的load加载入服务内存，这样当新的请求过来就会采用新的模型


资源集群
	凡是后端服务模块及计算任务模块均采用容器化在k8s上进行部署，利用k8s的自动扩缩容(水平增减实例和垂直增减单机cpu&内存)，完美保存服务的稳定性，可靠性和动态节省资源。如算法任务，可以数秒级启动数百容器进行数据计算，任务结束后立即回收掉容器资源。





